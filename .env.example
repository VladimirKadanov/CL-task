# Server Configuration
PORT=3000

# LLM Configuration
LLM_API_KEY=your-llm-api-key-here

# Optional: LLM Configuration (Defaults shown)
LLM_MODEL=gpt-3.5-turbo
LLM_MAX_TOKENS=1000
LLM_TEMPERATURE=0.7
LLM_BASE_URL= # Optional: Override the base URL for the LLM API (e.g., for proxies or local models)

# Optional: Logging Configuration
LOG_LEVEL=info
NODE_ENV=development

# Redis Configuration (Optional)
REDIS_URL=redis://localhost:6379
CACHE_TTL_SECONDS=3600 # Cache expiration time (1 hour) 